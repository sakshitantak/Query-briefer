{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_setup_query_briefer.ipynb","provenance":[],"mount_file_id":"1xyV1zKDwtgTSliqzHE6fYoyPrBWF-P4Y","authorship_tag":"ABX9TyOr5JPS9sRP515UlD3ufta2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gGCo69CtKsec"},"source":["#Directory location for repo in drive"]},{"cell_type":"code","metadata":{"id":"ZKoKeHI-14-D","executionInfo":{"status":"ok","timestamp":1603681146070,"user_tz":-330,"elapsed":1060,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"6a2f7cdd-14c0-4070-db56-a66dcf05b674","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /content/drive/My Drive/Colab Notebooks"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NCw2cgG2K0rL"},"source":["#Clone repo"]},{"cell_type":"code","metadata":{"id":"wUMsX5LkKjIb"},"source":["!git clone https://github.com/sosuperic/MeanSum.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zG6Fk6LTK7R-"},"source":["#Change priveleges of the file to run it and create new folders like output and checkpoints"]},{"cell_type":"code","metadata":{"id":"gygYdS51K58R"},"source":["!chmod 755 MeanSum/scripts/setup_dirs.sh\n","!MeanSum/scripts/setup_dirs.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XF_bIC6xLIHv"},"source":["#Change priveleges of the file to run it and do the necessary installations"]},{"cell_type":"code","metadata":{"id":"9NVfSbu3LOuF","executionInfo":{"status":"ok","timestamp":1603771718348,"user_tz":-330,"elapsed":184017,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"7e5b7471-d3c6-4712-f233-c9f13a059834","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!chmod 755 scripts/install_python_pkgs.sh\n","!scripts/install_python_pkgs.sh"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Collecting matplotlib==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/28/86488fe20a146241ece4570af94b49689ab80b66a1609256a8469a0bd1b0/matplotlib-2.0.0-1-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n","\u001b[K     |████████████████████████████████| 14.7MB 301kB/s \n","\u001b[?25hCollecting nltk==3.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/ce/cba8bf82c8ab538d444ea4ab6f4eb1d80340c7b737d7a8d1f08b429fccae/nltk-3.2.2.tar.gz (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 45.6MB/s \n","\u001b[?25hCollecting scipy==0.18.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/c0/f0bf4eaef1b6aa7bdd1ae5597ce1d9e729417b3ca085c47d0f1c640d34f8/scipy-0.18.1-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n","\u001b[K     |████████████████████████████████| 42.5MB 87kB/s \n","\u001b[?25hCollecting gensim==3.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n","\u001b[K     |████████████████████████████████| 22.6MB 1.4MB/s \n","\u001b[?25hCollecting numpy==1.15.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n","\u001b[K     |████████████████████████████████| 13.9MB 37.5MB/s \n","\u001b[?25hCollecting six==1.11.0\n","  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n","Collecting prettytable==0.7.2\n","  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n","Collecting scikit_learn==0.19.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/c8/8db4108aba5e2166cd2ea4eafa1a4b82f89240a1fa85733029cc2358ad1f/scikit_learn-0.19.2-cp36-cp36m-manylinux1_x86_64.whl (4.9MB)\n","\u001b[K     |████████████████████████████████| 4.9MB 37.4MB/s \n","\u001b[?25hCollecting tensorboardX==1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/22/43f4f0318f7c68a1000dbb700a353b745584bc2397437832d15ba69ea5f1/tensorboardX-1.2-py2.py3-none-any.whl (44kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n","\u001b[?25hCollecting tensorflow==1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n","\u001b[K     |████████████████████████████████| 83.1MB 46kB/s \n","\u001b[?25hCollecting torch==0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n","\u001b[K     |████████████████████████████████| 484.0MB 27kB/s \n","\u001b[?25hCollecting Unidecode==1.0.22\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n","\u001b[K     |████████████████████████████████| 235kB 46.5MB/s \n","\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.0->-r requirements.txt (line 1)) (0.10.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.0->-r requirements.txt (line 1)) (2018.9)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.0->-r requirements.txt (line 1)) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.0.0->-r requirements.txt (line 1)) (2.4.7)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.4.0->-r requirements.txt (line 4)) (3.0.0)\n","Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.2->-r requirements.txt (line 9)) (3.12.4)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (0.35.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (0.3.3)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (0.10.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (0.8.1)\n","Collecting tensorboard<1.13.0,>=1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 42.6MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (1.33.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 10)) (1.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.4.0->-r requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=0.3.2->tensorboardX==1.2->-r requirements.txt (line 9)) (50.3.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0->-r requirements.txt (line 10)) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 10)) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 10)) (3.3.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.4.0->-r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.4.0->-r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.4.0->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim==3.4.0->-r requirements.txt (line 4)) (2020.6.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 10)) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 10)) (3.3.1)\n","Building wheels for collected packages: nltk, prettytable\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.2.2-cp36-none-any.whl size=1353248 sha256=346969c012af4ec7c877ca0d0fbb1e9d22a36e9ede60350a011b02e767e8c0e8\n","  Stored in directory: /root/.cache/pip/wheels/64/db/e2/39e07b414a807d7aa0350c58417f61fd8654eca1fb5daf20b8\n","  Building wheel for prettytable (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for prettytable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=255f1da45f9d279a0fa0ecb80059685fb402d1728ea4276013476dca6ce44af8\n","  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n","Successfully built nltk prettytable\n","\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: umap-learn 0.4.6 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-hub 0.9.0 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: seaborn 0.11.0 has requirement matplotlib>=2.2, but you'll have matplotlib 2.0.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: seaborn 0.11.0 has requirement scipy>=1.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: scikit-image 0.16.2 has requirement scipy>=0.19.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pycocotools 2.0.2 has requirement matplotlib>=2.1.0, but you'll have matplotlib 2.0.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.0.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.0.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: dm-tree 0.1.5 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 0.18.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: astropy 4.1 has requirement numpy>=1.16, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: six, numpy, matplotlib, nltk, scipy, gensim, prettytable, scikit-learn, tensorboardX, keras-applications, tensorboard, tensorflow, torch, Unidecode\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","  Found existing installation: prettytable 1.0.1\n","    Uninstalling prettytable-1.0.1:\n","      Successfully uninstalled prettytable-1.0.1\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","  Found existing installation: torch 1.6.0+cu101\n","    Uninstalling torch-1.6.0+cu101:\n","      Successfully uninstalled torch-1.6.0+cu101\n","Successfully installed Unidecode-1.0.22 gensim-3.4.0 keras-applications-1.0.8 matplotlib-2.0.0 nltk-3.2.2 numpy-1.15.4 prettytable-0.7.2 scikit-learn-0.19.2 scipy-0.18.1 six-1.11.0 tensorboard-1.12.2 tensorboardX-1.2 tensorflow-1.12.0 torch-0.4.0\n","/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gcUeBMS2LdU5"},"source":["#Update tensorboard"]},{"cell_type":"code","metadata":{"id":"i3_IKntfLcq0","executionInfo":{"status":"ok","timestamp":1603771758727,"user_tz":-330,"elapsed":10918,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"fdced67a-828d-4b77-d611-083d3481ca4c","colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["!python scripts/update_tensorboard.py"],"execution_count":33,"outputs":[{"output_type":"stream","text":["cp tensorboard_application.py /usr//lib/python3.6/site-packages/tensorboard/backend/application.py\n","Reinstalling tensorboardx from source\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZfmBi-78MSLS"},"source":["#Run"]},{"cell_type":"code","metadata":{"id":"85CWL4SmP7qN","executionInfo":{"status":"ok","timestamp":1603772579234,"user_tz":-330,"elapsed":1021,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"4d0040ea-6de6-49b1-f4a4-6b7e2b81e2f0","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!pwd"],"execution_count":57,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/MeanSum\n","/bin/bash: line 0: cd: /data_loaders: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PFgd3GbIUWAe","executionInfo":{"status":"ok","timestamp":1603773019516,"user_tz":-330,"elapsed":3573,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"c2b3ce83-cd0c-4fad-b966-1311080b77bc","colab":{"base_uri":"https://localhost:8080/","height":259}},"source":["!python models/__init__.py\n","!python models/custom_parallel.py\n","!python models/mlstm.py\n","!python models/nn_utils.py\n","!python models/summarization.py\n","!python models/text_cnn.py"],"execution_count":65,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"models/mlstm.py\", line 12, in <module>\n","    from models.nn_utils import move_to_cuda, logits_to_prob, prob_to_vocab_id\n","ModuleNotFoundError: No module named 'models'\n","Traceback (most recent call last):\n","  File \"models/nn_utils.py\", line 12, in <module>\n","    from project_settings import PAD_ID\n","ModuleNotFoundError: No module named 'project_settings'\n","Traceback (most recent call last):\n","  File \"models/summarization.py\", line 13, in <module>\n","    from models.nn_utils import move_to_cuda, calc_clf_acc, convert_to_onehot, LabelSmoothing\n","ModuleNotFoundError: No module named 'models'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1VUQ_uqjQx-k","executionInfo":{"status":"ok","timestamp":1603772903680,"user_tz":-330,"elapsed":8129,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"10e9b1f5-b7b5-453e-dcd0-ecc1ba7839b4","colab":{"base_uri":"https://localhost:8080/","height":312}},"source":["!python data_loaders/__init__.py\n","#!python data_loaders/summ_dataset_factory.py\n","!python data_loaders/summ_dataset.py\n","!python data_loaders/build_subword_encoder.py\n","!python data_loaders/dataset_to_split_to_ids.json\n","!python data_loaders/text_encoder.py\n","!python data_loaders/tokenizer.py\n","!python data_loaders/yelp_dataset.py"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"data_loaders/summ_dataset.py\", line 10, in <module>\n","    from models.nn_utils import move_to_cuda\n","ModuleNotFoundError: No module named 'models'\n","Traceback (most recent call last):\n","  File \"data_loaders/build_subword_encoder.py\", line 33, in <module>\n","    from data_loaders import text_encoder, tokenizer\n","ModuleNotFoundError: No module named 'data_loaders'\n","Traceback (most recent call last):\n","  File \"data_loaders/text_encoder.py\", line 36, in <module>\n","    from data_loaders import tokenizer\n","ModuleNotFoundError: No module named 'data_loaders'\n","Traceback (most recent call last):\n","  File \"data_loaders/yelp_dataset.py\", line 19, in <module>\n","    from data_loaders.summ_dataset import SummReviewDataset, SummDataset\n","ModuleNotFoundError: No module named 'data_loaders'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OZN0XNgfMQFK","executionInfo":{"status":"ok","timestamp":1603772180546,"user_tz":-330,"elapsed":13168,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"794ad38f-7206-495f-f5c5-3faa5ec83235","colab":{"base_uri":"https://localhost:8080/","height":388}},"source":["!python train_sum.py --mode=test --gpus=0 --batch_size=16 --notes=multiAbSum"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Loading all items\n","Traceback (most recent call last):\n","  File \"train_sum.py\", line 1024, in <module>\n","    summarizer.test()\n","  File \"train_sum.py\", line 787, in test\n","    batch_size=self.hp.batch_size, shuffle=False)\n","  File \"/content/drive/My Drive/Colab Notebooks/MeanSum/data_loaders/yelp_dataset.py\", line 324, in get_data_loader\n","    item_max_reviews=self.conf.item_max_reviews)\n","  File \"/content/drive/My Drive/Colab Notebooks/MeanSum/data_loaders/yelp_dataset.py\", line 100, in __init__\n","    self.items = self.load_all_items()\n","  File \"/content/drive/My Drive/Colab Notebooks/MeanSum/data_loaders/yelp_dataset.py\", line 181, in load_all_items\n","    line = json.loads(line)\n","  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n","    return _default_decoder.decode(s)\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","  File \"/usr/lib/python3.6/json/decoder.py\", line 355, in raw_decode\n","    obj, end = self.scan_once(s, idx)\n","json.decoder.JSONDecodeError: Unterminated string starting at: line 1 column 409 (char 408)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pmcW_tZiL_jq"},"source":["#Later"]},{"cell_type":"code","metadata":{"id":"dP4A6P--Zw3t","executionInfo":{"status":"ok","timestamp":1603681080649,"user_tz":-330,"elapsed":6845,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}},"outputId":"33b3b6dc-f9c1-441e-fb2d-719b8819ae51","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["!pip install beautifulsoup4\n","!pip install google"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n","Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (2.0.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google) (4.6.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O3x7WZ6fPKOR","executionInfo":{"status":"ok","timestamp":1603681081380,"user_tz":-330,"elapsed":7136,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}}},"source":["from bs4 import BeautifulSoup\n","import re as re\n","import requests"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMI6VS7XaKK4","executionInfo":{"status":"ok","timestamp":1603641563859,"user_tz":-330,"elapsed":3499,"user":{"displayName":"Sakshi Tantak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt2ucPVxVe6YmK83hm2UGKPIaJBfp1g0T2pd5b97A=s64","userId":"10973988295865813050"}}},"source":["try:\n","    from googlesearch import search\n","except:\n","    print(\"No module named google found\")\n","\n","def get_urls(query, \n","             domain, \n","             top_k, \n","             lang=\"en\", pause=2.0):\n","  urls = []\n","  for i in search(query, \n","                  tld = domain, \n","                  lang=lang, \n","                  num=top_k, \n","                  start=0, \n","                  stop=top_k, \n","                  pause=pause):\n","    urls.append(i)\n","  return urls\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"GG1BJzEabAL_"},"source":["query = \"harappa\"\n","top_k = 3\n","#query = \"https://www.wikipedia.org/\" + query\n","urls = get_urls(query, \n","                \"com\", \n","                top_k, \n","                \"en\", \n","                2)\n","print(urls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"we4loOAYbNrn"},"source":["!git clone \"https://github.com/thecodelearner/rotating-proxy.git\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtsJA9X0ZWO6"},"source":["titles = []\n","bodies = []\n","all_tables = []\n","for url in urls:\n","  req = requests.get(url)\n","  soup = BeautifulSoup(req.text, \"lxml\")\n","  title = soup.title\n","  body_text = \"\"\n","  for body in soup.find_all(\"body\"):\n","    body_text += body.text\n","  \n","  titles.append(title)\n","  bodies.append(body_text)\n","\n","for title, body in zip(titles, bodies):\n","  print(f\"{title} : {body}\")\n","  print()"],"execution_count":null,"outputs":[]}]}